{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3162ba",
   "metadata": {},
   "source": [
    "# DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf604c",
   "metadata": {},
   "source": [
    "DataFrame is a distributed collection of data organized into named columns.\n",
    "It is normally an API built on top of RDDs.\n",
    "DF is conceptually equivalent to a table in a relational database or a data frame in Python, but with richer optimizations under the hood. \n",
    "DataFrames can be constructed from a wide array of sources such as:\n",
    "    structured data files\n",
    "    tables in Hive\n",
    "    external databases\n",
    "    existing RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e71e6f",
   "metadata": {},
   "source": [
    "Rows and Columns in DataFrames are nothing but Row Objects and Column Objects of Class:\n",
    "    pyspark.sql.Row\n",
    "    pyspark.sql.Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d67ca",
   "metadata": {},
   "source": [
    "# Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1056f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6b4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 08:06:56,686 WARN util.Utils: Your hostname, tb-LinuxBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "2021-09-21 08:06:56,688 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2021-09-21 08:06:59,038 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"DataFrame_basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37650219",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"count\"]\n",
    "data = [(\"Python\", 100000),(\"Java\",50000),(\"Scala\",8000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc661dbc",
   "metadata": {},
   "source": [
    "Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f780b16",
   "metadata": {},
   "source": [
    "There 2 wasy to create DataFrames from RDDs:\n",
    "    toDF(schema=None)\n",
    "    createDataFrame(data,schema=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06b9422b",
   "metadata": {},
   "source": [
    "1. toDF(schema=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3476a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8325019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rddToDF = dataRDD.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bcb1092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddToDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc3b666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rddToDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0dd414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddToDF.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42626b45",
   "metadata": {},
   "source": [
    "Default toDF() will put column names as _1 and _2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a7304c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"count\"]\n",
    "rddToDF = dataRDD.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd2fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|language| count|\n",
      "+--------+------+\n",
      "|  Python|100000|\n",
      "|    Java| 50000|\n",
      "|   Scala|  8000|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddToDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25c4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddToDF.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea9b2b99",
   "metadata": {},
   "source": [
    "2. createDataFrame(data,schema=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a0c497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"count\"]\n",
    "rddtoDF2 = spark.createDataFrame(data,schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "443b1f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|language| count|\n",
      "+--------+------+\n",
      "|  Python|100000|\n",
      "|    Java| 50000|\n",
      "|   Scala|  8000|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddtoDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3ff47c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddtoDF2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296e7f9",
   "metadata": {},
   "source": [
    "Create DataFrame from List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1ccbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"count\"]\n",
    "data = [(\"Python\", 100000),(\"Java\",50000),(\"Scala\",8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76894598",
   "metadata": {},
   "outputs": [],
   "source": [
    "listToDF = spark.createDataFrame(data,schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56fae00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|language| count|\n",
      "+--------+------+\n",
      "|  Python|100000|\n",
      "|    Java| 50000|\n",
      "|   Scala|  8000|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listToDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccaa3821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listToDF.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "533d2696",
   "metadata": {},
   "source": [
    "Create DataFrames from Row Object"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aae117ef",
   "metadata": {},
   "source": [
    "pyspark.sql.Row\n",
    "class pyspark.sql.Row\n",
    "\n",
    "A row in DataFrame. The fields in it can be accessed:\n",
    "like attributes (row.key)\n",
    "like dictionary values (row[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "062d411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b2d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data6 = map(lambda x: Row(x[0],x[1]),data) #returns a map object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94f6a500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7fed56a93700>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_data6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72dd1c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|language| count|\n",
      "+--------+------+\n",
      "|  Python|100000|\n",
      "|    Java| 50000|\n",
      "|   Scala|  8000|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(data=row_data6,schema=columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d5da8",
   "metadata": {},
   "source": [
    "# Create DataFrames with Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa77edc",
   "metadata": {},
   "source": [
    "from pyspark.sql import StructType, StructField\n",
    "\n",
    "StructType\n",
    "class pyspark.sql.types.StructType(fields=None)\n",
    "Struct type, consisting of a list of StructField.\n",
    "\n",
    "This is the data type representing a Row.\n",
    "\n",
    "Iterating a StructType will iterate over its StructFields. A contained StructField can be accessed by its name or position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1cfd94",
   "metadata": {},
   "source": [
    "StructField\n",
    "\n",
    "class pyspark.sql.types.StructField(name, dataType, nullable=True, metadata=None)[source]\n",
    "\n",
    "A field in StructType."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bfe0b",
   "metadata": {},
   "source": [
    "Important data types in pyspark.sql.types\n",
    "\n",
    "IntegerType() |\n",
    "FloatType() | \n",
    "StringType() | \n",
    "BooleanType() | \n",
    "TimestampType() | \n",
    "DateType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8a2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2e6b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "                     StructField(\"first_name\",StringType(),True)\\\n",
    "                     ,StructField(\"middle_name\",StringType(),True)\\\n",
    "                     ,StructField(\"last_name\",StringType(),False)\\\n",
    "                     ,StructField(\"id\",IntegerType(),False)\\\n",
    "                     ,StructField(\"gender\",StringType(),True)\\\n",
    "                     ,StructField(\"salary\",FloatType(),True)\\\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7e92f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\\\n",
    "        (\"Jonathan\",\"Don\",\"Snow\",100,'M',5000.50),\\\n",
    "        (\"Tony\",\"\",\"Stark\",200,'M',19000.00),\\\n",
    "        (\"Arya\",\"\",\"Stark\",0,'F',8000.50),\\\n",
    "        (\"Bruce\",\"Ben\",\"Banner\",400,'M',9000.80),\\\n",
    "        (\"Natasha\",\"Wonder\",\"Romanov\",500,'F',7000.50),\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "558a439e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17e5a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb205c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---+------+-------+\n",
      "|first_name|middle_name|last_name| id|gender| salary|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "|  Jonathan|        Don|     Snow|100|     M| 5000.5|\n",
      "|      Tony|           |    Stark|200|     M|19000.0|\n",
      "|      Arya|           |    Stark|  0|     F| 8000.5|\n",
      "|     Bruce|        Ben|   Banner|400|     M| 9000.8|\n",
      "|   Natasha|     Wonder|  Romanov|500|     F| 7000.5|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01161d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = false)\n",
      " |-- id: integer (nullable = false)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c90af",
   "metadata": {},
   "source": [
    "# Create DataFrame from Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e4d46",
   "metadata": {},
   "source": [
    "csv, txt, json, parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a6481",
   "metadata": {},
   "source": [
    "The APIs are present in pyspark.sql.readwriter inside DataFrameReader class:<br>\n",
    "Important methods from class DataFrameReader:<br>\n",
    "\n",
    "1. format(self, source) -> Specifies the input data source format<br>\n",
    "2. schema(self, schema) -> Specifies the input schema<br>\n",
    "        Some data sources (e.g. JSON) can infer the input schema automatically from data.\n",
    "        By specifying the schema here, the underlying data source can skip the schema\n",
    "        inference step, and thus speed up data loading.<br>\n",
    "3. option(self, key, value) -> Adds an input option for the underlying data source (doubt)<br>\n",
    "4. load(self, path=None, format=None, schema=None, **options)<br>\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str or list, optional\n",
    "            optional string or a list of string for file-system backed data sources.\n",
    "        format : str, optional\n",
    "            optional string for format of the data source. Default to 'parquet'.\n",
    "        schema : :class:`pyspark.sql.types.StructType` or str, optional\n",
    "            optional :class:`pyspark.sql.types.StructType` for the input schema\n",
    "            or a DDL-formatted string (For example ``col0 INT, col1 DOUBLE``).\n",
    "        **options : dict\n",
    "            all other string options<br>\n",
    "<br>\n",
    "5. json(self, path, mode=None, compression=None, dateFormat=None, timestampFormat=None,<br>\n",
    "                 lineSep=None, encoding=None, ignoreNullFields=None)<br>\n",
    "                 -> Loads JSON files and returns the results as a :class:`DataFrame`<br>\n",
    "<br>\n",
    "6. table(self, tableName) -> Returns the specified table as a :class:`DataFrame`<br>\n",
    "<br>\n",
    "7. parquet(self, *paths, **options) -> Loads Parquet files, returning the result as a :class:`DataFrame`<br>\n",
    "<br>\n",
    "    important options: recursiveFileLookup<br>\n",
    "<br>\n",
    "    modifiedBefore (batch only) : an optional timestamp to only include files with\n",
    "        modification times occurring before the specified time. The provided timestamp\n",
    "        must be in the following format: YYYY-MM-DDTHH:mm:ss (e.g. 2020-06-01T13:00:00)\n",
    "<br>\n",
    "    modifiedAfter (batch only) : an optional timestamp to only include files with\n",
    "        modification times occurring after the specified time. The provided timestamp\n",
    "        must be in the following format: YYYY-MM-DDTHH:mm:ss (e.g. 2020-06-01T13:00:00)<br>\n",
    "<br>\n",
    "8. text(self, paths, wholetext=False, lineSep=None, pathGlobFilter=None,<br>\n",
    "             recursiveFileLookup=None, modifiedBefore=None,<br>\n",
    "             modifiedAfter=None) -> <br>\n",
    "<br>\n",
    "            Loads text files and returns a :class:`DataFrame` whose schema starts with a\n",
    "            string column named \"value\", and followed by partitioned columns if there\n",
    "            are any.\n",
    "            The text files must be encoded as UTF-8.\n",
    "<br>\n",
    "            By default, each line in the text file is a new row in the resulting DataFrame.<br>\n",
    "<br>\n",
    "9. csv(self, path, schema=None, sep=None, encoding=None, quote=None, escape=None,<br>\n",
    "            comment=None, header=None, inferSchema=None, ignoreLeadingWhiteSpace=None,<br>\n",
    "            ignoreTrailingWhiteSpace=None, nullValue=None, nanValue=None, positiveInf=None,<br>\n",
    "            negativeInf=None, dateFormat=None, timestampFormat=None, maxColumns=None,<br>\n",
    "            maxCharsPerColumn=None, maxMalformedLogPerPartition=None, mode=None,<br>\n",
    "            columnNameOfCorruptRecord=None, multiLine=None, charToEscapeQuoteEscaping=None,<br>\n",
    "            samplingRatio=None, enforceSchema=None, emptyValue=None, locale=None, lineSep=None,<br>\n",
    "            pathGlobFilter=None, recursiveFileLookup=None, modifiedBefore=None, modifiedAfter=None,<br>\n",
    "            unescapedQuoteHandling=None) <br>\n",
    "            -> Loads a CSV file and returns the result as a  :class:`DataFrame`<br>\n",
    "<br>\n",
    "10. saveAsTable(self, name, format=None, mode=None, partitionBy=None, **options)<br>\n",
    "            -> Saves the content of the :class:`DataFrame` as the specified table.<br>\n",
    "                In the case the table already exists, behavior of this function depends on the\n",
    "                save mode, specified by the `mode` function (default to throwing an exception).\n",
    "                When `mode` is `Overwrite`, the schema of the :class:`DataFrame` does not need to be\n",
    "                the same as that of the existing table.<br>\n",
    "\n",
    "                * `append`: Append contents of this :class:`DataFrame` to existing data.\n",
    "                * `overwrite`: Overwrite existing data.\n",
    "                * `error` or `errorifexists`: Throw an exception if data already exists.\n",
    "                * `ignore`: Silently ignore this operation if data already exists.<br>\n",
    "<br>\n",
    "11. partitionBy(self, *cols) ->\n",
    "            Partitions the output by the given columns on the file system.<br>\n",
    "<br>\n",
    "12. bucketBy(self, numBuckets, col, *cols) ->\n",
    "            Buckets the output by the given columns.If specified,\n",
    "            the output is laid out on the file system similar to Hive's bucketing scheme.<br>\n",
    "<br>\n",
    "13. sortBy(self, col, *cols) ->\n",
    "            Sorts the output in each bucket by the given columns on the file system.<br>\n",
    "<br>\n",
    "14. jdbc(self, url, table, mode=None, properties=None):\n",
    "        Saves the content of the :class:`DataFrame` to an external database table via JDBC.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7458535e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csvDF = spark.read.format(\"csv\").options(header=True).load(\"/sparkdata/CarPrice_Assignment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbace292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 08:07:41,900 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------------------+--------+----------+----------+-----------+----------+--------------+---------+---------+--------+---------+----------+----------+--------------+----------+----------+---------+------+----------------+----------+-------+-------+----------+-----+\n",
      "|car_ID|symboling|            CarName|fueltype|aspiration|doornumber|    carbody|drivewheel|enginelocation|wheelbase|carlength|carwidth|carheight|curbweight|enginetype|cylindernumber|enginesize|fuelsystem|boreratio|stroke|compressionratio|horsepower|peakrpm|citympg|highwaympg|price|\n",
      "+------+---------+-------------------+--------+----------+----------+-----------+----------+--------------+---------+---------+--------+---------+----------+----------+--------------+----------+----------+---------+------+----------------+----------+-------+-------+----------+-----+\n",
      "|     1|        3| alfa-romero giulia|     gas|       std|       two|convertible|       rwd|         front|     88.6|    168.8|    64.1|     48.8|      2548|      dohc|          four|       130|      mpfi|     3.47|  2.68|               9|       111|   5000|     21|        27|13495|\n",
      "|     2|        3|alfa-romero stelvio|     gas|       std|       two|convertible|       rwd|         front|     88.6|    168.8|    64.1|     48.8|      2548|      dohc|          four|       130|      mpfi|     3.47|  2.68|               9|       111|   5000|     21|        27|16500|\n",
      "+------+---------+-------------------+--------+----------+----------+-----------+----------+--------------+---------+---------+--------+---------+----------+----------+--------------+----------+----------+---------+------+----------------+----------+-------+-------+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c645ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDF = spark.read.format(\"text\").options(header=True).load(\"/sparkdata/word_count_data2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb5d2941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Now the way that ...|\n",
      "|that the robbers ...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txtDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f61fb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDF = spark.read.format(\"json\").options(header=True).load(\"/sparkdata/store_locations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "787264e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------+\n",
      "|    city|state| zip_code|\n",
      "+--------+-----+---------+\n",
      "| Antioch|   CA|945097911|\n",
      "|Woodland|   CA|957765409|\n",
      "+--------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txtDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c318a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "txtDF = spark.read.format(\"parquet\").options(header=True).load(\"/sparkdata/parquet_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cce8dbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "|order_item_id|order_item_order_id|order_item_product_id|order_item_quantity|order_item_subtotal|order_item_product_price|\n",
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "|            1|                  1|                  957|                  1|             299.98|                  299.98|\n",
      "|            2|                  2|                 1073|                  1|             199.99|                  199.99|\n",
      "|            3|                  2|                  502|                  5|              250.0|                    50.0|\n",
      "|            4|                  2|                  403|                  1|             129.99|                  129.99|\n",
      "|            5|                  4|                  897|                  2|              49.98|                   24.99|\n",
      "|            6|                  4|                  365|                  5|             299.95|                   59.99|\n",
      "|            7|                  4|                  502|                  3|              150.0|                    50.0|\n",
      "|            8|                  4|                 1014|                  4|             199.92|                   49.98|\n",
      "|            9|                  5|                  957|                  1|             299.98|                  299.98|\n",
      "|           10|                  5|                  365|                  5|             299.95|                   59.99|\n",
      "|           11|                  5|                 1014|                  2|              99.96|                   49.98|\n",
      "|           12|                  5|                  957|                  1|             299.98|                  299.98|\n",
      "|           13|                  5|                  403|                  1|             129.99|                  129.99|\n",
      "|           14|                  7|                 1073|                  1|             199.99|                  199.99|\n",
      "|           15|                  7|                  957|                  1|             299.98|                  299.98|\n",
      "|           16|                  7|                  926|                  5|              79.95|                   15.99|\n",
      "|           17|                  8|                  365|                  3|             179.97|                   59.99|\n",
      "|           18|                  8|                  365|                  5|             299.95|                   59.99|\n",
      "|           19|                  8|                 1014|                  4|             199.92|                   49.98|\n",
      "|           20|                  8|                  502|                  1|               50.0|                    50.0|\n",
      "+-------------+-------------------+---------------------+-------------------+-------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "txtDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc52d7",
   "metadata": {},
   "source": [
    "# Convert RDD to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b4b9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"count\"]\n",
    "data = [(\"Python\", 100000),(\"Java\",50000),(\"Scala\",8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34fbd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRDD = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88201bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 100000), ('Java', 50000), ('Scala', 8000)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleRDD.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30f3b4bd",
   "metadata": {},
   "source": [
    "Using toDF(schema=none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b2f74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddToDF = sampleRDD.toDF(schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a477502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|language| count|\n",
      "+--------+------+\n",
      "|  Python|100000|\n",
      "|    Java| 50000|\n",
      "|   Scala|  8000|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddToDF.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "232f3998",
   "metadata": {},
   "source": [
    "Using createDataFrame(data,schema=none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05819931",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be66d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddToDF2 = spark.createDataFrame(sampleRDD, schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7f778e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|language| count|\n",
      "+--------+------+\n",
      "|  Python|100000|\n",
      "|    Java| 50000|\n",
      "|   Scala|  8000|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rddToDF2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485ee31",
   "metadata": {},
   "source": [
    "# Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a169e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\\\n",
    "        (\"Jonathon\",\"Don\",\"Snow\",100,\"M\",5000.00)\\\n",
    "        ,(\"Arya\",\"K\",\"Stark\",101,\"F\",10000.00)\\\n",
    "        ,(\"Steve\",\"S\",\"Rogers\",102,\"M\",8000.00)\\\n",
    "        ,(\"Natasha\",\"J\",\"Romanov\",103,\"F\",19000.00)\\\n",
    "        ,(\"Tyrion\",\"K\",\"Lannister\",104,\"M\",11000.00)\\\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caf3df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"first_name\",\"middle_name\",\"last_name\",\"id\",\"gender\",\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3042d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24c6d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---+------+-------+\n",
      "|first_name|middle_name|last_name| id|gender| salary|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "|  Jonathon|        Don|     Snow|100|     M| 5000.0|\n",
      "|      Arya|          K|    Stark|101|     F|10000.0|\n",
      "|     Steve|          S|   Rogers|102|     M| 8000.0|\n",
      "|   Natasha|          J|  Romanov|103|     F|19000.0|\n",
      "|    Tyrion|          K|Lannister|104|     M|11000.0|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a74d2c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|first_name| salary|\n",
      "+----------+-------+\n",
      "|  Jonathon| 5000.0|\n",
      "|      Arya|10000.0|\n",
      "|     Steve| 8000.0|\n",
      "|   Natasha|19000.0|\n",
      "|    Tyrion|11000.0|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"first_name\",\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5efee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|first_name| salary|\n",
      "+----------+-------+\n",
      "|  Jonathon| 5000.0|\n",
      "|      Arya|10000.0|\n",
      "|     Steve| 8000.0|\n",
      "|   Natasha|19000.0|\n",
      "|    Tyrion|11000.0|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.first_name,df.salary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5be72dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|first_name| salary|\n",
      "+----------+-------+\n",
      "|  Jonathon| 5000.0|\n",
      "|      Arya|10000.0|\n",
      "|     Steve| 8000.0|\n",
      "|   Natasha|19000.0|\n",
      "|    Tyrion|11000.0|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"first_name\"],df[\"salary\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84b92e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|first_name| salary|\n",
      "+----------+-------+\n",
      "|  Jonathon| 5000.0|\n",
      "|      Arya|10000.0|\n",
      "|     Steve| 8000.0|\n",
      "|   Natasha|19000.0|\n",
      "|    Tyrion|11000.0|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"first_name\"),col(\"salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88aeeaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---+------+-------+\n",
      "|first_name|middle_name|last_name| id|gender| salary|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "|  Jonathon|        Don|     Snow|100|     M| 5000.0|\n",
      "|      Arya|          K|    Stark|101|     F|10000.0|\n",
      "|     Steve|          S|   Rogers|102|     M| 8000.0|\n",
      "|   Natasha|          J|  Romanov|103|     F|19000.0|\n",
      "|    Tyrion|          K|Lannister|104|     M|11000.0|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1322f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---+------+\n",
      "|middle_name|last_name| id|gender|\n",
      "+-----------+---------+---+------+\n",
      "|        Don|     Snow|100|     M|\n",
      "|          K|    Stark|101|     F|\n",
      "|          S|   Rogers|102|     M|\n",
      "|          J|  Romanov|103|     F|\n",
      "|          K|Lannister|104|     M|\n",
      "+-----------+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(columns[1:5]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa294957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|last_name|\n",
      "+---------+\n",
      "|     Snow|\n",
      "|    Stark|\n",
      "|   Rogers|\n",
      "|  Romanov|\n",
      "|Lannister|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(columns[2]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2193c2",
   "metadata": {},
   "source": [
    "# Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2608d7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(first_name='Jonathon', middle_name='Don', last_name='Snow', id=100, gender='M', salary=5000.0),\n",
       " Row(first_name='Arya', middle_name='K', last_name='Stark', id=101, gender='F', salary=10000.0),\n",
       " Row(first_name='Steve', middle_name='S', last_name='Rogers', id=102, gender='M', salary=8000.0),\n",
       " Row(first_name='Natasha', middle_name='J', last_name='Romanov', id=103, gender='F', salary=19000.0),\n",
       " Row(first_name='Tyrion', middle_name='K', last_name='Lannister', id=104, gender='M', salary=11000.0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e471849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(first_name='Jonathon', middle_name='Don', last_name='Snow', id=100, gender='M', salary=5000.0)\n",
      "Row(first_name='Arya', middle_name='K', last_name='Stark', id=101, gender='F', salary=10000.0)\n",
      "Row(first_name='Steve', middle_name='S', last_name='Rogers', id=102, gender='M', salary=8000.0)\n",
      "Row(first_name='Natasha', middle_name='J', last_name='Romanov', id=103, gender='F', salary=19000.0)\n",
      "Row(first_name='Tyrion', middle_name='K', last_name='Lannister', id=104, gender='M', salary=11000.0)\n"
     ]
    }
   ],
   "source": [
    "for i in df.collect(): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c212129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Jonathon', 'Don', 'Snow', 100, 'M', 5000.0)\n",
      "('Arya', 'K', 'Stark', 101, 'F', 10000.0)\n",
      "('Steve', 'S', 'Rogers', 102, 'M', 8000.0)\n",
      "('Natasha', 'J', 'Romanov', 103, 'F', 19000.0)\n",
      "('Tyrion', 'K', 'Lannister', 104, 'M', 11000.0)\n"
     ]
    }
   ],
   "source": [
    "for i in df.collect(): print(i[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe58198",
   "metadata": {},
   "source": [
    "# withColumn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e110d55",
   "metadata": {},
   "source": [
    "Used to change value, convert data type of existing column, create new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d66eeb",
   "metadata": {},
   "source": [
    "def withColumn(self, colName, col):\n",
    "        \"\"\"\n",
    "        Returns a new :class:`DataFrame` by adding a column or replacing the\n",
    "        existing column that has the same name.\n",
    "\n",
    "        The column expression must be an expression over this :class:`DataFrame`; attempting to add\n",
    "        a column from some other :class:`DataFrame` will raise an error.\n",
    "\n",
    "        .. versionadded:: 1.3.0\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        colName : str\n",
    "            string, name of the new column.\n",
    "        col : :class:`Column`\n",
    "            a :class:`Column` expression for the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "811b1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\\\n",
    "        (\"Jonathon\",\"Don\",\"Snow\",\"100\",\"M\",\"5000.00\")\\\n",
    "        ,(\"Arya\",\"K\",\"Stark\",\"101\",\"F\",\"10000.00\")\\\n",
    "        ,(\"Steve\",\"S\",\"Rogers\",\"102\",\"M\",\"8000.00\")\\\n",
    "        ,(\"Natasha\",\"J\",\"Romanov\",\"103\",\"F\",\"19000.00\")\\\n",
    "        ,(\"Tyrion\",\"K\",\"Lannister\",\"104\",\"M\",\"11000.00\")\\\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "081838ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"first_name\",\"middle_name\",\"last_name\",\"id\",\"gender\",\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fb6cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data,schema=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ad48233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---+------+--------+\n",
      "|first_name|middle_name|last_name| id|gender|  salary|\n",
      "+----------+-----------+---------+---+------+--------+\n",
      "|  Jonathon|        Don|     Snow|100|     M| 5000.00|\n",
      "|      Arya|          K|    Stark|101|     F|10000.00|\n",
      "|     Steve|          S|   Rogers|102|     M| 8000.00|\n",
      "|   Natasha|          J|  Romanov|103|     F|19000.00|\n",
      "|    Tyrion|          K|Lannister|104|     M|11000.00|\n",
      "+----------+-----------+---------+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16642fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e8883f2",
   "metadata": {},
   "source": [
    "Cast data type from one to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98d955d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca1648c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"id\",df.id.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e111756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbbe04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"salary\",df.salary.cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22530cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d22eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase salary by 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "103fa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"salary\",df.salary*1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2c4c6aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---+------+-------+\n",
      "|first_name|middle_name|last_name| id|gender| salary|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "|  Jonathon|        Don|     Snow|100|     M| 6000.0|\n",
      "|      Arya|          K|    Stark|101|     F|12000.0|\n",
      "|     Steve|          S|   Rogers|102|     M| 9600.0|\n",
      "|   Natasha|          J|  Romanov|103|     F|22800.0|\n",
      "|    Tyrion|          K|Lannister|104|     M|13200.0|\n",
      "+----------+-----------+---------+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62b214ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d96a5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f969b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(  \\\n",
    "                    \"full_gender\",\\\n",
    "                    when(df.gender == 'F',lit(\"Female\"))\\\n",
    "                   .when(df.gender == 'M',\"Male\").otherwise(\"NA\")\\\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b376806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---+------+-------+-----------+\n",
      "|first_name|middle_name|last_name| id|gender| salary|full_gender|\n",
      "+----------+-----------+---------+---+------+-------+-----------+\n",
      "|  Jonathon|        Don|     Snow|100|     M| 6000.0|       Male|\n",
      "|      Arya|          K|    Stark|101|     F|12000.0|     Female|\n",
      "|     Steve|          S|   Rogers|102|     M| 9600.0|       Male|\n",
      "|   Natasha|          J|  Romanov|103|     F|22800.0|     Female|\n",
      "|    Tyrion|          K|Lannister|104|     M|13200.0|       Male|\n",
      "+----------+-----------+---------+---+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5a5c52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---+------+-------+-----------+\n",
      "|first_name|last_name| id|gender| salary|full_gender|\n",
      "+----------+---------+---+------+-------+-----------+\n",
      "|  Jonathon|     Snow|100|     M| 6000.0|       Male|\n",
      "|      Arya|    Stark|101|     F|12000.0|     Female|\n",
      "|     Steve|   Rogers|102|     M| 9600.0|       Male|\n",
      "|   Natasha|  Romanov|103|     F|22800.0|     Female|\n",
      "|    Tyrion|Lannister|104|     M|13200.0|       Male|\n",
      "+----------+---------+---+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.middle_name).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e9ebc",
   "metadata": {},
   "source": [
    "withColumnRenamed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "377b38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"id\", \"id_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1c4b213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---------+------+-------+-----------+\n",
      "|first_name|middle_name|last_name|id_number|gender| salary|full_gender|\n",
      "+----------+-----------+---------+---------+------+-------+-----------+\n",
      "|  Jonathon|        Don|     Snow|      100|     M| 6000.0|       Male|\n",
      "|      Arya|          K|    Stark|      101|     F|12000.0|     Female|\n",
      "|     Steve|          S|   Rogers|      102|     M| 9600.0|       Male|\n",
      "|   Natasha|          J|  Romanov|      103|     F|22800.0|     Female|\n",
      "|    Tyrion|          K|Lannister|      104|     M|13200.0|       Male|\n",
      "+----------+-----------+---------+---------+------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d392d18",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c300b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5a96746",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "        ((\"Jonathan\",\"Don\",\"Snow\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "        ((\"Daniel\",\"C\",\"Targ\"),[\"Java\",\"Go\",\"C++\"],\"NY\",\"F\"),\n",
    "        ((\"Tyrion\",\"K\",\"Lannister\"),[\"Python\",\"Scala\",\"C\"],\"NC\",\"M\"),\n",
    "        ((\"Arya\",\"F\",\"Stark\"),[\"JavaScript\",\"HTML\",\"CSS\"],\"WA\",\"F\"),\n",
    "        ((\"Cersei\",\"\",\"Lannister\"),[\"Python\",\"Scala\",\"Java\"],\"CA\",\"M\"),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "007a6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "                    StructField(\"name\",StructType([\n",
    "                                                    StructField(\"first_name\",StringType(),True),\n",
    "                                                    StructField(\"middle_name\",StringType(),True),\n",
    "                                                    StructField(\"last_name\",StringType(),True)\n",
    "                                                ]),True),\n",
    "                    StructField(\"languages\", ArrayType(StringType()),True),\n",
    "                    StructField(\"state\", StringType(),True),\n",
    "                    StructField(\"gender\", StringType(),True),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07e0babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc15eca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------------+-----+------+\n",
      "|name                  |languages              |state|gender|\n",
      "+----------------------+-----------------------+-----+------+\n",
      "|{Jonathan, Don, Snow} |[Java, Scala, C++]     |OH   |M     |\n",
      "|{Daniel, C, Targ}     |[Java, Go, C++]        |NY   |F     |\n",
      "|{Tyrion, K, Lannister}|[Python, Scala, C]     |NC   |M     |\n",
      "|{Arya, F, Stark}      |[JavaScript, HTML, CSS]|WA   |F     |\n",
      "|{Cersei, , Lannister} |[Python, Scala, Java]  |CA   |M     |\n",
      "+----------------------+-----------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb73a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- middle_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "baaa5f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|{Tyrion, K, Lannister}|[Python, Scala, C]|NC   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state == 'NC').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d759d1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------------+-----+------+\n",
      "|name                 |languages              |state|gender|\n",
      "+---------------------+-----------------------+-----+------+\n",
      "|{Jonathan, Don, Snow}|[Java, Scala, C++]     |OH   |M     |\n",
      "|{Daniel, C, Targ}    |[Java, Go, C++]        |NY   |F     |\n",
      "|{Arya, F, Stark}     |[JavaScript, HTML, CSS]|WA   |F     |\n",
      "|{Cersei, , Lannister}|[Python, Scala, Java]  |CA   |M     |\n",
      "+---------------------+-----------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state != 'NC').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef842ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------+-----+------+\n",
      "|name             |languages              |state|gender|\n",
      "+-----------------+-----------------------+-----+------+\n",
      "|{Daniel, C, Targ}|[Java, Go, C++]        |NY   |F     |\n",
      "|{Arya, F, Stark} |[JavaScript, HTML, CSS]|WA   |F     |\n",
      "+-----------------+-----------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.state != 'NC')&(df.gender == 'F')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e6d23ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|{Jonathan, Don, S...|[Java, Scala, C++]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.isin([\"OH\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c760a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|{Daniel, C, Targ}     |[Java, Go, C++]   |NY   |F     |\n",
      "|{Tyrion, K, Lannister}|[Python, Scala, C]|NC   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.startswith(\"N\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6798e8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|{Daniel, C, Targ}     |[Java, Go, C++]   |NY   |F     |\n",
      "|{Tyrion, K, Lannister}|[Python, Scala, C]|NC   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.state.like(\"N%\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7c30f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "04ccb9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------+-----+------+\n",
      "|name                  |languages            |state|gender|\n",
      "+----------------------+---------------------+-----+------+\n",
      "|{Tyrion, K, Lannister}|[Python, Scala, C]   |NC   |M     |\n",
      "|{Cersei, , Lannister} |[Python, Scala, Java]|CA   |M     |\n",
      "+----------------------+---------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(array_contains(df.languages,\"Python\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8809b177",
   "metadata": {},
   "source": [
    "# Distinct and DropDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5caed676",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"name\",\"depatment\",\"salary\"]\n",
    "data = [\n",
    "        (\"Jonathan\",\"Sales\",6500),\\\n",
    "        (\"Arya\",\"Developer\",10000),\\\n",
    "        (\"Tony\",\"Developer\",10000),\\\n",
    "        (\"Bruce\",\"Manager\",15000),\\\n",
    "        (\"Tony\",\"Developer\",10000),\\\n",
    "        (\"Arya\",\"Developer\",10000),\\\n",
    "        (\"Sansa\",\"Sales\",8000),\\\n",
    "        (\"Jamie\",\"Sales\",6000),\\\n",
    "        (\"Tyrion\",\"Director\",20000),\\\n",
    "        (\"Jonathan\",\"Sales\",5000),\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e85becf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f72c0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    name|depatment|salary|\n",
      "+--------+---------+------+\n",
      "|Jonathan|    Sales|  6500|\n",
      "|    Arya|Developer| 10000|\n",
      "|    Tony|Developer| 10000|\n",
      "|   Bruce|  Manager| 15000|\n",
      "|    Tony|Developer| 10000|\n",
      "|    Arya|Developer| 10000|\n",
      "|   Sansa|    Sales|  8000|\n",
      "|   Jamie|    Sales|  6000|\n",
      "|  Tyrion| Director| 20000|\n",
      "|Jonathan|    Sales|  5000|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22b1adb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    name|depatment|salary|\n",
      "+--------+---------+------+\n",
      "|Jonathan|    Sales|  6500|\n",
      "|   Sansa|    Sales|  8000|\n",
      "|   Bruce|  Manager| 15000|\n",
      "|Jonathan|    Sales|  5000|\n",
      "|    Tony|Developer| 10000|\n",
      "|    Arya|Developer| 10000|\n",
      "|  Tyrion| Director| 20000|\n",
      "|   Jamie|    Sales|  6000|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 82:========================================>               (54 + 2) / 75]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.distinct().show() \n",
    "#This runs a distinct on all row object. \n",
    "#For a row to be eliminated due to distinct, it has to contain all the fieelds redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c7f2c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 90:============================================>          (80 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    name|depatment|salary|\n",
      "+--------+---------+------+\n",
      "|Jonathan|    Sales|  6500|\n",
      "|   Sansa|    Sales|  8000|\n",
      "|   Bruce|  Manager| 15000|\n",
      "|Jonathan|    Sales|  5000|\n",
      "|    Tony|Developer| 10000|\n",
      "|    Arya|Developer| 10000|\n",
      "|  Tyrion| Director| 20000|\n",
      "|   Jamie|    Sales|  6000|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates().show()\n",
    "#Same as distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4cc46e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:==============================================>       (173 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    name|depatment|salary|\n",
      "+--------+---------+------+\n",
      "|    Arya|Developer| 10000|\n",
      "|   Bruce|  Manager| 15000|\n",
      "|   Jamie|    Sales|  6000|\n",
      "|Jonathan|    Sales|  6500|\n",
      "|Jonathan|    Sales|  5000|\n",
      "|   Sansa|    Sales|  8000|\n",
      "|  Tyrion| Director| 20000|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 94:===================================================>  (192 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates(subset=[\"salary\",\"depatment\"]).orderBy(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c86b4",
   "metadata": {},
   "source": [
    "# sort and orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7139770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"name\",\"depatment\",\"salary\"]\n",
    "data = [\n",
    "        (\"Jonathan\",\"Sales\",6500),\\\n",
    "        (\"Arya\",\"Developer\",10000),\\\n",
    "        (\"Tony\",\"Developer\",10000),\\\n",
    "        (\"Bruce\",\"Manager\",15000),\\\n",
    "        (\"Tony\",\"Developer\",10000),\\\n",
    "        (\"Arya\",\"Developer\",10000),\\\n",
    "        (\"Sansa\",\"Sales\",8000),\\\n",
    "        (\"Jamie\",\"Sales\",6000),\\\n",
    "        (\"Tyrion\",\"Director\",20000),\\\n",
    "        (\"Jonathan\",\"Sales\",5000),\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86bbd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7f581f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    name|depatment|salary|\n",
      "+--------+---------+------+\n",
      "|Jonathan|    Sales|  6500|\n",
      "|    Arya|Developer| 10000|\n",
      "|    Tony|Developer| 10000|\n",
      "|   Bruce|  Manager| 15000|\n",
      "|    Tony|Developer| 10000|\n",
      "|    Arya|Developer| 10000|\n",
      "|   Sansa|    Sales|  8000|\n",
      "|   Jamie|    Sales|  6000|\n",
      "|  Tyrion| Director| 20000|\n",
      "|Jonathan|    Sales|  5000|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2974e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    name|depatment|salary|\n",
      "+--------+---------+------+\n",
      "|  Tyrion| Director| 20000|\n",
      "|   Bruce|  Manager| 15000|\n",
      "|    Arya|Developer| 10000|\n",
      "|    Arya|Developer| 10000|\n",
      "|    Tony|Developer| 10000|\n",
      "|    Tony|Developer| 10000|\n",
      "|   Sansa|    Sales|  8000|\n",
      "|Jonathan|    Sales|  6500|\n",
      "|   Jamie|    Sales|  6000|\n",
      "|Jonathan|    Sales|  5000|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.salary.desc(),df.name).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e1ee3f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+\n",
      "|    name|depatment|salary|\n",
      "+--------+---------+------+\n",
      "|  Tyrion| Director| 20000|\n",
      "|   Bruce|  Manager| 15000|\n",
      "|    Arya|Developer| 10000|\n",
      "|    Arya|Developer| 10000|\n",
      "|    Tony|Developer| 10000|\n",
      "|    Tony|Developer| 10000|\n",
      "|   Sansa|    Sales|  8000|\n",
      "|Jonathan|    Sales|  6500|\n",
      "|   Jamie|    Sales|  6000|\n",
      "|Jonathan|    Sales|  5000|\n",
      "+--------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.salary.desc(),df.name).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317a6bd",
   "metadata": {},
   "source": [
    "# groupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb83c2",
   "metadata": {},
   "source": [
    "groupBy() collects identical rows into groups and performs an aggregation on a given column per grouped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fbbcae",
   "metadata": {},
   "source": [
    "When we perform groupBy() on PySpark Dataframe, it returns GroupedData object which contains below aggregate functions.\n",
    "\n",
    "count() - Returns the count of rows for each group.<br>\n",
    "mean() - Returns the mean of values for each group.<br>\n",
    "max() - Returns the maximum of values for each group.<br> \n",
    "min() - Returns the minimum of values for each group.<br>\n",
    "sum() - Returns the total for values for each group.<br>\n",
    "avg() - Returns the average for values for each group.<br> \n",
    "agg() - Using agg() function, we can calculate more than one aggregate at a time.<br>\n",
    "pivot() - This function is used to Pivot the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f2b1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "data = [\n",
    "        (\"Jonathan\",\"Developer\",\"NC\",90000,35,2000),\\\n",
    "        (\"Tony\",\"Developer\",\"NY\",120000,45,3000),\\\n",
    "        (\"Arya\",\"Developer\",\"NC\",95000,18,4000),\\\n",
    "        (\"Bruce\",\"Sales\",\"CA\",100000,58,1000),\\\n",
    "        (\"Natasha\",\"Sales\",\"CA\",80000,40,5000),\\\n",
    "        (\"Steve\",\"Sales\",\"WA\",70000,28,8000),\\\n",
    "        (\"Thanos\",\"Finance\",\"NC\",60000,75,3000),\\\n",
    "        (\"Sansa\",\"Developer\",\"WA\",90000,23,9000),\\\n",
    "        (\"Gandalf\",\"Finance\",\"NY\",150000,80,2000),\\\n",
    "        (\"Cercei\",\"Finance\",\"NC\",85000,46,2500),\\\n",
    "        (\"Thor\",\"Sales\",\"WA\",75000,50,5000),\\\n",
    "        (\"Messi\",\"Developer\",\"NY\",130000,34,6000),\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa5b2d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2b7d1891",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|     Jonathan| Developer|   NC| 90000| 35| 2000|\n",
      "|         Tony| Developer|   NY|120000| 45| 3000|\n",
      "|         Arya| Developer|   NC| 95000| 18| 4000|\n",
      "|        Bruce|     Sales|   CA|100000| 58| 1000|\n",
      "|      Natasha|     Sales|   CA| 80000| 40| 5000|\n",
      "|        Steve|     Sales|   WA| 70000| 28| 8000|\n",
      "|       Thanos|   Finance|   NC| 60000| 75| 3000|\n",
      "|        Sansa| Developer|   WA| 90000| 23| 9000|\n",
      "|      Gandalf|   Finance|   NY|150000| 80| 2000|\n",
      "|       Cercei|   Finance|   NC| 85000| 46| 2500|\n",
      "|         Thor|     Sales|   WA| 75000| 50| 5000|\n",
      "|        Messi| Developer|   NY|130000| 34| 6000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e379724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7fed56aa10d0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(df.department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e2c54fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|department|max(salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|     100000|\n",
      "|   Finance|     150000|\n",
      "| Developer|     130000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.department).max(\"salary\").show() #do not pur df.salary -> does not take a Row() object. Instead a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0252776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+\n",
      "|department|max(salary)|max(age)|\n",
      "+----------+-----------+--------+\n",
      "|     Sales|     100000|      58|\n",
      "|   Finance|     150000|      80|\n",
      "| Developer|     130000|      45|\n",
      "+----------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.department).max(\"salary\",\"age\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89357c9d",
   "metadata": {},
   "source": [
    "groupBy on multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9de984b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 128:==============================================>       (86 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+--------+----------+\n",
      "|department|state|avg(salary)|avg(age)|avg(bonus)|\n",
      "+----------+-----+-----------+--------+----------+\n",
      "|   Finance|   NY|   150000.0|    80.0|    2000.0|\n",
      "|     Sales|   CA|    90000.0|    49.0|    3000.0|\n",
      "|     Sales|   WA|    72500.0|    39.0|    6500.0|\n",
      "| Developer|   WA|    90000.0|    23.0|    9000.0|\n",
      "|   Finance|   NC|    72500.0|    60.5|    2750.0|\n",
      "| Developer|   NY|   125000.0|    39.5|    4500.0|\n",
      "| Developer|   NC|    92500.0|    26.5|    3000.0|\n",
      "+----------+-----+-----------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.department,df.state).mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5226eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 138:=====================================================>(99 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+----------+\n",
      "|department|state|sum(salary)|sum(bonus)|\n",
      "+----------+-----+-----------+----------+\n",
      "|   Finance|   NY|     150000|      2000|\n",
      "|     Sales|   CA|     180000|      6000|\n",
      "|     Sales|   WA|     145000|     13000|\n",
      "| Developer|   WA|      90000|      9000|\n",
      "|   Finance|   NC|     145000|      5500|\n",
      "| Developer|   NY|     250000|      9000|\n",
      "| Developer|   NC|     185000|      6000|\n",
      "+----------+-----+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.department,df.state).sum(\"salary\",\"bonus\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e5bda377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,mean,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fbfb51ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 148:===================================================>  (95 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---------+---------+\n",
      "|department|salary_sum|salary_max|bonus_sum|bonus_max|\n",
      "+----------+----------+----------+---------+---------+\n",
      "|     Sales|    325000|    100000|    19000|     8000|\n",
      "|   Finance|    295000|    150000|     7500|     3000|\n",
      "| Developer|    525000|    130000|    24000|     9000|\n",
      "+----------+----------+----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.department).agg(\n",
    "                                sum(\"salary\").alias(\"salary_sum\"),\\\n",
    "                                max(\"salary\").alias(\"salary_max\"),\\\n",
    "                                sum(\"bonus\").alias(\"bonus_sum\"),\\\n",
    "                                max(\"bonus\").alias(\"bonus_max\"),\\\n",
    "\n",
    "                            ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba09cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 160:==========================================>            (58 + 3) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---------+---------+\n",
      "|department|salary_sum|salary_max|bonus_sum|bonus_max|\n",
      "+----------+----------+----------+---------+---------+\n",
      "|     Sales|    325000|    100000|    19000|     8000|\n",
      "| Developer|    525000|    130000|    24000|     9000|\n",
      "+----------+----------+----------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.department).agg(\n",
    "                                sum(\"salary\").alias(\"salary_sum\"),\\\n",
    "                                max(\"salary\").alias(\"salary_max\"),\\\n",
    "                                sum(\"bonus\").alias(\"bonus_sum\"),\\\n",
    "                                max(\"bonus\").alias(\"bonus_max\"),\\\n",
    "\n",
    "                            ).filter(\"bonus_max > 3000\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9becff7",
   "metadata": {},
   "source": [
    "# Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bad85b",
   "metadata": {},
   "source": [
    "join(self,other,on=None,how=None) <br>\n",
    "df1.join(df2.on=\"column_name\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c87c0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "department_schema = [\"department_id\",\"department_name\"]\n",
    "department = [\n",
    "            (10,\"finance\")\n",
    "            ,(20,\"sales\")\n",
    "            ,(30,\"developer\")\n",
    "            ,(40,\"hr\")\n",
    "            ,(50,\"Admin\")\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "56d1e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_schema = [\"emp_id\",\"emp_name\",\"emp_manager_id\",\"year_of_joining\", \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "employee = [\n",
    "            (1,\"Jonathan\",15,\"2019\",30,\"M\",90000),\n",
    "            (2,\"Tyrion\",5,\"2015\",40,\"M\",80000),\n",
    "            (3,\"Arya\",10,\"2020\",20,\"F\",80000),\n",
    "            (4,\"Thanos\",19,\"2010\",10,\"M\",110000),\n",
    "            (5,\"Tony\",19,\"2015\",40,\"M\",150000),\n",
    "            (6,\"Danny\",15,\"2018\",30,\"F\",70000),\n",
    "            (7,\"Natasha\",4,\"2019\",10,\"F\",95000),\n",
    "            (8,\"Bruce\",10,\"2021\",20,\"M\",60000),\n",
    "            (9,\"Sam\",15,\"2014\",30,\"M\",80000),\n",
    "            (10,\"Cercei\",19,\"2012\",20,\"F\",120000),\n",
    "            (11,\"Varis\",5,\"2016\",40,\"M\",65000),\n",
    "            (12,\"Jamie\",4,\"2013\",10,\"M\",95000),\n",
    "            (13,\"Wanda\",10,\"2017\",20,\"F\",75000),\n",
    "            (14,\"Sansa\",4,\"2018\",10,\"F\",100000),\n",
    "            (15,\"Loki\",5,\"2020\",40,\"M\",70000),\n",
    "            (16,\"Ned\",19,\"2011\",30,\"M\",160000),\n",
    "            (17,\"Cap_Marvel\",19,\"2021\",60,\"F\",50000),\n",
    "            (18,\"Hound\",17,\"2021\",60,\"M\",450000),\n",
    "            (19,\"Fury\",0,\"2010\",0,\"M\",200000),\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1c91f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deptDF = spark.createDataFrame(data=department,schema=department_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "487cb2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|department_id|department_name|\n",
      "+-------------+---------------+\n",
      "|           10|        finance|\n",
      "|           20|          sales|\n",
      "|           30|      developer|\n",
      "|           40|             hr|\n",
      "|           50|          Admin|\n",
      "+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deptDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b15e1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "empDF = spark.createDataFrame(data=employee,schema=employee_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f45dc877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|emp_id|  emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|     1|  Jonathan|            15|           2019|         30|     M| 90000|\n",
      "|     2|    Tyrion|             5|           2015|         40|     M| 80000|\n",
      "|     3|      Arya|            10|           2020|         20|     F| 80000|\n",
      "|     4|    Thanos|            19|           2010|         10|     M|110000|\n",
      "|     5|      Tony|            19|           2015|         40|     M|150000|\n",
      "|     6|     Danny|            15|           2018|         30|     F| 70000|\n",
      "|     7|   Natasha|             4|           2019|         10|     F| 95000|\n",
      "|     8|     Bruce|            10|           2021|         20|     M| 60000|\n",
      "|     9|       Sam|            15|           2014|         30|     M| 80000|\n",
      "|    10|    Cercei|            19|           2012|         20|     F|120000|\n",
      "|    11|     Varis|             5|           2016|         40|     M| 65000|\n",
      "|    12|     Jamie|             4|           2013|         10|     M| 95000|\n",
      "|    13|     Wanda|            10|           2017|         20|     F| 75000|\n",
      "|    14|     Sansa|             4|           2018|         10|     F|100000|\n",
      "|    15|      Loki|             5|           2020|         40|     M| 70000|\n",
      "|    16|       Ned|            19|           2011|         30|     M|160000|\n",
      "|    17|Cap_Marvel|            19|           2021|         60|     F| 50000|\n",
      "|    18|     Hound|            17|           2021|         60|     M|450000|\n",
      "|    19|      Fury|             0|           2010|          0|     M|200000|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4202ea85",
   "metadata": {},
   "source": [
    "Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "703d7cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 213:===========================================>         (164 + 3) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|emp_id|emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|department_id|department_name|\n",
      "+------+--------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|     1|Jonathan|            15|           2019|         30|     M| 90000|           30|      developer|\n",
      "|     2|  Tyrion|             5|           2015|         40|     M| 80000|           40|             hr|\n",
      "|     3|    Arya|            10|           2020|         20|     F| 80000|           20|          sales|\n",
      "|     4|  Thanos|            19|           2010|         10|     M|110000|           10|        finance|\n",
      "|     5|    Tony|            19|           2015|         40|     M|150000|           40|             hr|\n",
      "|     6|   Danny|            15|           2018|         30|     F| 70000|           30|      developer|\n",
      "|     7| Natasha|             4|           2019|         10|     F| 95000|           10|        finance|\n",
      "|     8|   Bruce|            10|           2021|         20|     M| 60000|           20|          sales|\n",
      "|     9|     Sam|            15|           2014|         30|     M| 80000|           30|      developer|\n",
      "|    10|  Cercei|            19|           2012|         20|     F|120000|           20|          sales|\n",
      "|    11|   Varis|             5|           2016|         40|     M| 65000|           40|             hr|\n",
      "|    12|   Jamie|             4|           2013|         10|     M| 95000|           10|        finance|\n",
      "|    13|   Wanda|            10|           2017|         20|     F| 75000|           20|          sales|\n",
      "|    14|   Sansa|             4|           2018|         10|     F|100000|           10|        finance|\n",
      "|    15|    Loki|             5|           2020|         40|     M| 70000|           40|             hr|\n",
      "|    16|     Ned|            19|           2011|         30|     M|160000|           30|      developer|\n",
      "+------+--------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 213:==================================================>  (190 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.department_id,how=\"inner\").orderBy(empDF.emp_id).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0f099",
   "metadata": {},
   "source": [
    "Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "876816e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 216:==========================================>          (161 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|emp_id|  emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|department_id|department_name|\n",
      "+------+----------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|     1|  Jonathan|            15|           2019|         30|     M| 90000|           30|      developer|\n",
      "|     2|    Tyrion|             5|           2015|         40|     M| 80000|           40|             hr|\n",
      "|     3|      Arya|            10|           2020|         20|     F| 80000|           20|          sales|\n",
      "|     4|    Thanos|            19|           2010|         10|     M|110000|           10|        finance|\n",
      "|     5|      Tony|            19|           2015|         40|     M|150000|           40|             hr|\n",
      "|     6|     Danny|            15|           2018|         30|     F| 70000|           30|      developer|\n",
      "|     7|   Natasha|             4|           2019|         10|     F| 95000|           10|        finance|\n",
      "|     8|     Bruce|            10|           2021|         20|     M| 60000|           20|          sales|\n",
      "|     9|       Sam|            15|           2014|         30|     M| 80000|           30|      developer|\n",
      "|    10|    Cercei|            19|           2012|         20|     F|120000|           20|          sales|\n",
      "|    11|     Varis|             5|           2016|         40|     M| 65000|           40|             hr|\n",
      "|    12|     Jamie|             4|           2013|         10|     M| 95000|           10|        finance|\n",
      "|    13|     Wanda|            10|           2017|         20|     F| 75000|           20|          sales|\n",
      "|    14|     Sansa|             4|           2018|         10|     F|100000|           10|        finance|\n",
      "|    15|      Loki|             5|           2020|         40|     M| 70000|           40|             hr|\n",
      "|    16|       Ned|            19|           2011|         30|     M|160000|           30|      developer|\n",
      "|    17|Cap_Marvel|            19|           2021|         60|     F| 50000|         null|           null|\n",
      "|    18|     Hound|            17|           2021|         60|     M|450000|         null|           null|\n",
      "|    19|      Fury|             0|           2010|          0|     M|200000|         null|           null|\n",
      "+------+----------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 216:================================================>    (182 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.department_id,how=\"left\").orderBy(empDF.emp_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a5039260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 219:========================================>            (151 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|emp_id|emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|department_id|department_name|\n",
      "+------+--------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|  null|    null|          null|           null|       null|  null|  null|           50|          Admin|\n",
      "|     1|Jonathan|            15|           2019|         30|     M| 90000|           30|      developer|\n",
      "|     2|  Tyrion|             5|           2015|         40|     M| 80000|           40|             hr|\n",
      "|     3|    Arya|            10|           2020|         20|     F| 80000|           20|          sales|\n",
      "|     4|  Thanos|            19|           2010|         10|     M|110000|           10|        finance|\n",
      "|     5|    Tony|            19|           2015|         40|     M|150000|           40|             hr|\n",
      "|     6|   Danny|            15|           2018|         30|     F| 70000|           30|      developer|\n",
      "|     7| Natasha|             4|           2019|         10|     F| 95000|           10|        finance|\n",
      "|     8|   Bruce|            10|           2021|         20|     M| 60000|           20|          sales|\n",
      "|     9|     Sam|            15|           2014|         30|     M| 80000|           30|      developer|\n",
      "|    10|  Cercei|            19|           2012|         20|     F|120000|           20|          sales|\n",
      "|    11|   Varis|             5|           2016|         40|     M| 65000|           40|             hr|\n",
      "|    12|   Jamie|             4|           2013|         10|     M| 95000|           10|        finance|\n",
      "|    13|   Wanda|            10|           2017|         20|     F| 75000|           20|          sales|\n",
      "|    14|   Sansa|             4|           2018|         10|     F|100000|           10|        finance|\n",
      "|    15|    Loki|             5|           2020|         40|     M| 70000|           40|             hr|\n",
      "|    16|     Ned|            19|           2011|         30|     M|160000|           30|      developer|\n",
      "+------+--------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 219:============================================>        (168 + 2) / 200]\r",
      "\r",
      "[Stage 219:=================================================>   (188 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.department_id,how=\"right\").orderBy(empDF.emp_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a237c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 222:=================================================>   (187 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|emp_id|  emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|department_id|department_name|\n",
      "+------+----------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "|  null|      null|          null|           null|       null|  null|  null|           50|          Admin|\n",
      "|     1|  Jonathan|            15|           2019|         30|     M| 90000|           30|      developer|\n",
      "|     2|    Tyrion|             5|           2015|         40|     M| 80000|           40|             hr|\n",
      "|     3|      Arya|            10|           2020|         20|     F| 80000|           20|          sales|\n",
      "|     4|    Thanos|            19|           2010|         10|     M|110000|           10|        finance|\n",
      "|     5|      Tony|            19|           2015|         40|     M|150000|           40|             hr|\n",
      "|     6|     Danny|            15|           2018|         30|     F| 70000|           30|      developer|\n",
      "|     7|   Natasha|             4|           2019|         10|     F| 95000|           10|        finance|\n",
      "|     8|     Bruce|            10|           2021|         20|     M| 60000|           20|          sales|\n",
      "|     9|       Sam|            15|           2014|         30|     M| 80000|           30|      developer|\n",
      "|    10|    Cercei|            19|           2012|         20|     F|120000|           20|          sales|\n",
      "|    11|     Varis|             5|           2016|         40|     M| 65000|           40|             hr|\n",
      "|    12|     Jamie|             4|           2013|         10|     M| 95000|           10|        finance|\n",
      "|    13|     Wanda|            10|           2017|         20|     F| 75000|           20|          sales|\n",
      "|    14|     Sansa|             4|           2018|         10|     F|100000|           10|        finance|\n",
      "|    15|      Loki|             5|           2020|         40|     M| 70000|           40|             hr|\n",
      "|    16|       Ned|            19|           2011|         30|     M|160000|           30|      developer|\n",
      "|    17|Cap_Marvel|            19|           2021|         60|     F| 50000|         null|           null|\n",
      "|    18|     Hound|            17|           2021|         60|     M|450000|         null|           null|\n",
      "|    19|      Fury|             0|           2010|          0|     M|200000|         null|           null|\n",
      "+------+----------+--------------+---------------+-----------+------+------+-------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.department_id,how=\"fullouter\").orderBy(empDF.emp_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2149301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 225:============================================>        (167 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|emp_id|  emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|    17|Cap_Marvel|            19|           2021|         60|     F| 50000|\n",
      "|    18|     Hound|            17|           2021|         60|     M|450000|\n",
      "|    19|      Fury|             0|           2010|          0|     M|200000|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 225:================================================>    (182 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id==deptDF.department_id,how=\"leftanti\").orderBy(empDF.emp_id).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc1a51",
   "metadata": {},
   "source": [
    "# Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f29c7",
   "metadata": {},
   "source": [
    "Merging 2 DataFrames with same schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d1bd8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp1_schema = [\"emp_id\",\"emp_name\",\"emp_manager_id\",\"year_of_joining\", \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "emp1 = [\n",
    "            (1,\"Jonathan\",15,\"2019\",30,\"M\",90000),\n",
    "            (2,\"Tyrion\",5,\"2015\",40,\"M\",80000),\n",
    "            (3,\"Arya\",10,\"2020\",20,\"F\",80000),\n",
    "            (4,\"Thanos\",19,\"2010\",10,\"M\",110000),\n",
    "            (5,\"Tony\",19,\"2015\",40,\"M\",150000),\n",
    "            (6,\"Danny\",15,\"2018\",30,\"F\",70000),\n",
    "            (7,\"Natasha\",4,\"2019\",10,\"F\",95000),\n",
    "            (8,\"Bruce\",10,\"2021\",20,\"M\",60000),\n",
    "            (9,\"Sam\",15,\"2014\",30,\"M\",80000),\n",
    "        ]\n",
    "\n",
    "emp2_schema = [\"emp_id\",\"emp_name\",\"emp_manager_id\",\"year_of_joining\", \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "emp2= [\n",
    "            (10,\"Cercei\",19,\"2012\",20,\"F\",120000),\n",
    "            (11,\"Varis\",5,\"2016\",40,\"M\",65000),\n",
    "            (12,\"Jamie\",4,\"2013\",10,\"M\",95000),\n",
    "            (13,\"Wanda\",10,\"2017\",20,\"F\",75000),\n",
    "            (14,\"Sansa\",4,\"2018\",10,\"F\",100000),\n",
    "            (15,\"Loki\",5,\"2020\",40,\"M\",70000),\n",
    "            (16,\"Ned\",19,\"2011\",30,\"M\",160000),\n",
    "            (17,\"Cap_Marvel\",19,\"2021\",60,\"F\",50000),\n",
    "            (18,\"Hound\",17,\"2021\",60,\"M\",450000),\n",
    "            (19,\"Fury\",0,\"2010\",0,\"M\",200000),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7bc440dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp1DF = spark.createDataFrame(emp1,emp1_schema)\n",
    "emp2DF = spark.createDataFrame(emp2,emp2_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ef715edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------+---------------+-----------+------+------+\n",
      "|emp_id|emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|\n",
      "+------+--------+--------------+---------------+-----------+------+------+\n",
      "|     1|Jonathan|            15|           2019|         30|     M| 90000|\n",
      "|     2|  Tyrion|             5|           2015|         40|     M| 80000|\n",
      "|     3|    Arya|            10|           2020|         20|     F| 80000|\n",
      "|     4|  Thanos|            19|           2010|         10|     M|110000|\n",
      "|     5|    Tony|            19|           2015|         40|     M|150000|\n",
      "|     6|   Danny|            15|           2018|         30|     F| 70000|\n",
      "|     7| Natasha|             4|           2019|         10|     F| 95000|\n",
      "|     8|   Bruce|            10|           2021|         20|     M| 60000|\n",
      "|     9|     Sam|            15|           2014|         30|     M| 80000|\n",
      "+------+--------+--------------+---------------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "42c6a692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|emp_id|  emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|    10|    Cercei|            19|           2012|         20|     F|120000|\n",
      "|    11|     Varis|             5|           2016|         40|     M| 65000|\n",
      "|    12|     Jamie|             4|           2013|         10|     M| 95000|\n",
      "|    13|     Wanda|            10|           2017|         20|     F| 75000|\n",
      "|    14|     Sansa|             4|           2018|         10|     F|100000|\n",
      "|    15|      Loki|             5|           2020|         40|     M| 70000|\n",
      "|    16|       Ned|            19|           2011|         30|     M|160000|\n",
      "|    17|Cap_Marvel|            19|           2021|         60|     F| 50000|\n",
      "|    18|     Hound|            17|           2021|         60|     M|450000|\n",
      "|    19|      Fury|             0|           2010|          0|     M|200000|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp2DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2b48d687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|emp_id|  emp_name|emp_manager_id|year_of_joining|emp_dept_id|gender|salary|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "|     1|  Jonathan|            15|           2019|         30|     M| 90000|\n",
      "|     2|    Tyrion|             5|           2015|         40|     M| 80000|\n",
      "|     3|      Arya|            10|           2020|         20|     F| 80000|\n",
      "|     4|    Thanos|            19|           2010|         10|     M|110000|\n",
      "|     5|      Tony|            19|           2015|         40|     M|150000|\n",
      "|     6|     Danny|            15|           2018|         30|     F| 70000|\n",
      "|     7|   Natasha|             4|           2019|         10|     F| 95000|\n",
      "|     8|     Bruce|            10|           2021|         20|     M| 60000|\n",
      "|     9|       Sam|            15|           2014|         30|     M| 80000|\n",
      "|    10|    Cercei|            19|           2012|         20|     F|120000|\n",
      "|    11|     Varis|             5|           2016|         40|     M| 65000|\n",
      "|    12|     Jamie|             4|           2013|         10|     M| 95000|\n",
      "|    13|     Wanda|            10|           2017|         20|     F| 75000|\n",
      "|    14|     Sansa|             4|           2018|         10|     F|100000|\n",
      "|    15|      Loki|             5|           2020|         40|     M| 70000|\n",
      "|    16|       Ned|            19|           2011|         30|     M|160000|\n",
      "|    17|Cap_Marvel|            19|           2021|         60|     F| 50000|\n",
      "|    18|     Hound|            17|           2021|         60|     M|450000|\n",
      "|    19|      Fury|             0|           2010|          0|     M|200000|\n",
      "+------+----------+--------------+---------------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1DF.union(emp2DF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bcfee",
   "metadata": {},
   "source": [
    "# unionByName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4de5f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_schema = [\"id\",\"name\",\"dept\",\"salary\"]\n",
    "data1 = [\n",
    "    (1,\"Jon\",\"sales\",5000),\n",
    "    (2,\"Danny\",\"finance\",6000),\n",
    "    (3,\"Arya\",\"admin\",4000),\n",
    "    (4,\"Ned\",\"sales\",7000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d113145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_schema = [\"id\",\"name\",\"dept\",\"join_year\"]\n",
    "data2 = [\n",
    "    (1,\"Jon\",\"sales\",\"2019\"),\n",
    "    (2,\"Danny\",\"finance\",\"2018\"),\n",
    "    (3,\"Arya\",\"admin\",\"2020\"),\n",
    "    (4,\"Ned\",\"sales\",\"2010\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "51b498c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(data1,data1_schema)\n",
    "df2 = spark.createDataFrame(data2,data2_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "be76b190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+------+\n",
      "| id| name|   dept|salary|\n",
      "+---+-----+-------+------+\n",
      "|  1|  Jon|  sales|  5000|\n",
      "|  2|Danny|finance|  6000|\n",
      "|  3| Arya|  admin|  4000|\n",
      "|  4|  Ned|  sales|  7000|\n",
      "+---+-----+-------+------+\n",
      "\n",
      "None\n",
      "+---+-----+-------+---------+\n",
      "| id| name|   dept|join_year|\n",
      "+---+-----+-------+---------+\n",
      "|  1|  Jon|  sales|     2019|\n",
      "|  2|Danny|finance|     2018|\n",
      "|  3| Arya|  admin|     2020|\n",
      "|  4|  Ned|  sales|     2010|\n",
      "+---+-----+-------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1.show())\n",
    "print(df2.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1d7aed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+------+\n",
      "| id| name|   dept|salary|\n",
      "+---+-----+-------+------+\n",
      "|  1|  Jon|  sales|  5000|\n",
      "|  2|Danny|finance|  6000|\n",
      "|  3| Arya|  admin|  4000|\n",
      "|  4|  Ned|  sales|  7000|\n",
      "|  1|  Jon|  sales|  2019|\n",
      "|  2|Danny|finance|  2018|\n",
      "|  3| Arya|  admin|  2020|\n",
      "|  4|  Ned|  sales|  2010|\n",
      "+---+-----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "743174f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+---------+\n",
      "| id| name|   dept|join_year|\n",
      "+---+-----+-------+---------+\n",
      "|  1|  Jon|  sales|     2019|\n",
      "|  2|Danny|finance|     2018|\n",
      "|  3| Arya|  admin|     2020|\n",
      "|  4|  Ned|  sales|     2010|\n",
      "|  1|  Jon|  sales|     5000|\n",
      "|  2|Danny|finance|     6000|\n",
      "|  3| Arya|  admin|     4000|\n",
      "|  4|  Ned|  sales|     7000|\n",
      "+---+-----+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.union(df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b4c8f7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+------+---------+\n",
      "| id| name|   dept|salary|join_year|\n",
      "+---+-----+-------+------+---------+\n",
      "|  1|  Jon|  sales|  5000|     null|\n",
      "|  2|Danny|finance|  6000|     null|\n",
      "|  3| Arya|  admin|  4000|     null|\n",
      "|  4|  Ned|  sales|  7000|     null|\n",
      "|  1|  Jon|  sales|  null|     2019|\n",
      "|  2|Danny|finance|  null|     2018|\n",
      "|  3| Arya|  admin|  null|     2020|\n",
      "|  4|  Ned|  sales|  null|     2010|\n",
      "+---+-----+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionByName(df2,allowMissingColumns=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8d6c8",
   "metadata": {},
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58a3c1",
   "metadata": {},
   "source": [
    "UDFs - User Defined Functions Python functions that are not covered by existing Pyspark functions.<br>\n",
    "<br>\n",
    "UDFs need to be created using udf() function in order to use as a Pyspark function.<br>\n",
    "UDFs must be registered using udf.register() function in order to be used in Pyspark SQL.<br>\n",
    "<br>\n",
    "Performance of UDFs are not good as for Pyspark, UDFs are a black box and Pyspark Optimization techniques cannot be applied on UDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "83fce25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\"id\",\"first_name\",\"last_name\",\"dept\",\"salary\"]\n",
    "data = [\n",
    "    (1,\"jon\",\"Snow\",\"sales\",5000),\n",
    "    (2,\"danny\",\"Targy\",\"finance\",6000),\n",
    "    (3,\"arya\",\"Stark\",\"admin\",4000),\n",
    "    (4,\"ned\",\"Stark\",\"sales\",7000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "82515989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "15060ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------+------+\n",
      "| id|first_name|last_name|   dept|salary|\n",
      "+---+----------+---------+-------+------+\n",
      "|  1|       jon|     Snow|  sales|  5000|\n",
      "|  2|     danny|    Targy|finance|  6000|\n",
      "|  3|      arya|    Stark|  admin|  4000|\n",
      "|  4|       ned|    Stark|  sales|  7000|\n",
      "+---+----------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f866715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requirement - \n",
    "# 1. change first letter of first_name into uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "211a162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_case(word):\n",
    "    '''Takes a word as input and returns the word with first letter in upper case\n",
    "    Example: convert_case(\"jon\") returns Jon'''\n",
    "    return word[0].upper() + word[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b9e0678",
   "metadata": {},
   "source": [
    "Converting Python function to UDF - creating UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "109ec950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ba129608",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_case_udf_for_Pyspark = udf(lambda word: convert_case(word), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "aa05efba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'<lambda>()'>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_case_udf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c81b48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using UDF in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5ca05f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "        df.id,\n",
    "        convert_case_udf_for_Pyspark(df.first_name).alias(\"fname_caps\"),\n",
    "        df.last_name,\n",
    "        df.dept,\n",
    "        df.salary\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0474f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------+------+\n",
      "| id|fname_caps|last_name|   dept|salary|\n",
      "+---+----------+---------+-------+------+\n",
      "|  1|       Jon|     Snow|  sales|  5000|\n",
      "|  2|     Danny|    Targy|finance|  6000|\n",
      "|  3|      Arya|    Stark|  admin|  4000|\n",
      "|  4|       Ned|    Stark|  sales|  7000|\n",
      "+---+----------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5316fa6",
   "metadata": {},
   "source": [
    "Registering UDF: IN order to use Python functions in Pyspark SQL, we need to register UDF.<br>\n",
    "UDF Registration:<br>\n",
    "spark.udf.register(UDF_name,Python_function,returnType=None) -> Register a Python function (including lambda function) or a user-defined function\n",
    "as a SQL function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4b652478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 13:21:12,596 WARN analysis.SimpleFunctionRegistry: The function convert_case_udf_for_sql replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.convert_case(word)>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"convert_case_udf_for_sql\",convert_case,returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ebc6e0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------+------+\n",
      "| id|first_name|last_name|   dept|salary|\n",
      "+---+----------+---------+-------+------+\n",
      "|  1|       jon|     Snow|  sales|  5000|\n",
      "|  2|     danny|    Targy|finance|  6000|\n",
      "|  3|      arya|    Stark|  admin|  4000|\n",
      "|  4|       ned|    Stark|  sales|  7000|\n",
      "+---+----------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f7d63fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "81dccfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------+------+\n",
      "| id|first_name|last_name|   dept|salary|\n",
      "+---+----------+---------+-------+------+\n",
      "|  1|       jon|     Snow|  sales|  5000|\n",
      "|  2|     danny|    Targy|finance|  6000|\n",
      "|  3|      arya|    Stark|  admin|  4000|\n",
      "|  4|       ned|    Stark|  sales|  7000|\n",
      "+---+----------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from temp_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0adbd267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+---------+-------+------+\n",
      "| id|first_name_conv|last_name|   dept|salary|\n",
      "+---+---------------+---------+-------+------+\n",
      "|  1|            Jon|     Snow|  sales|  5000|\n",
      "|  2|          Danny|    Targy|finance|  6000|\n",
      "|  3|           Arya|    Stark|  admin|  4000|\n",
      "|  4|            Ned|    Stark|  sales|  7000|\n",
      "+---+---------------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id,convert_case_udf_for_sql(first_name) as first_name_conv,last_name,dept,salary from temp_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "def5fbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------+------+\n",
      "| id|first_name|last_name|   dept|salary|\n",
      "+---+----------+---------+-------+------+\n",
      "|  1|       jon|     Snow|  sales|  5000|\n",
      "|  2|     danny|    Targy|finance|  6000|\n",
      "|  3|      arya|    Stark|  admin|  4000|\n",
      "|  4|       ned|    Stark|  sales|  7000|\n",
      "+---+----------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6edd61",
   "metadata": {},
   "source": [
    "# partitionBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "559f01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrameWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "72151582",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "data = [\n",
    "        (\"Jonathan\",\"Developer\",\"NC\",90000,35,2000),\\\n",
    "        (\"Tony\",\"Developer\",\"NY\",120000,45,3000),\\\n",
    "        (\"Arya\",\"Developer\",\"NC\",95000,18,4000),\\\n",
    "        (\"Bruce\",\"Sales\",\"CA\",100000,58,1000),\\\n",
    "        (\"Natasha\",\"Sales\",\"CA\",80000,40,5000),\\\n",
    "        (\"Steve\",\"Sales\",\"WA\",70000,28,8000),\\\n",
    "        (\"Thanos\",\"Finance\",\"NC\",60000,75,3000),\\\n",
    "        (\"Sansa\",\"Developer\",\"WA\",90000,23,9000),\\\n",
    "        (\"Gandalf\",\"Finance\",\"NY\",150000,80,2000),\\\n",
    "        (\"Cercei\",\"Finance\",\"NC\",85000,46,2500),\\\n",
    "        (\"Thor\",\"Sales\",\"WA\",75000,50,5000),\\\n",
    "        (\"Messi\",\"Developer\",\"NY\",130000,34,6000),\\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "961e1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3e3461bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|     Jonathan| Developer|   NC| 90000| 35| 2000|\n",
      "|         Tony| Developer|   NY|120000| 45| 3000|\n",
      "|         Arya| Developer|   NC| 95000| 18| 4000|\n",
      "|        Bruce|     Sales|   CA|100000| 58| 1000|\n",
      "|      Natasha|     Sales|   CA| 80000| 40| 5000|\n",
      "|        Steve|     Sales|   WA| 70000| 28| 8000|\n",
      "|       Thanos|   Finance|   NC| 60000| 75| 3000|\n",
      "|        Sansa| Developer|   WA| 90000| 23| 9000|\n",
      "|      Gandalf|   Finance|   NY|150000| 80| 2000|\n",
      "|       Cercei|   Finance|   NC| 85000| 46| 2500|\n",
      "|         Thor|     Sales|   WA| 75000| 50| 5000|\n",
      "|        Messi| Developer|   NY|130000| 34| 6000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5e92888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.option(\"header\",True).partitionBy(\"state\").csv(\"/sparkdata/partitionby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 directories will form in the mentioned file location"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56bcf4b1",
   "metadata": {},
   "source": [
    "Found 5 items\n",
    "-rw-r--r--   1 tamaghna supergroup          0 2021-09-21 17:55 /sparkdata/partitionby/_SUCCESS\n",
    "drwxr-xr-x   - tamaghna supergroup          0 2021-09-21 17:55 /sparkdata/partitionby/state=CA\n",
    "drwxr-xr-x   - tamaghna supergroup          0 2021-09-21 17:55 /sparkdata/partitionby/state=NC\n",
    "drwxr-xr-x   - tamaghna supergroup          0 2021-09-21 17:55 /sparkdata/partitionby/state=NY\n",
    "drwxr-xr-x   - tamaghna supergroup          0 2021-09-21 17:55 /sparkdata/partitionby/state=WA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135b94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
