{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da2a9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f62c05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"broadcast_join\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b19982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = spark.read.format(\"parquet\")\\\n",
    "                    .options(header=True)\\\n",
    "                    .load(\"file:///home/tamaghna/big_data_spark/sales_parquet\")\n",
    "\n",
    "sellers = spark.read.format(\"parquet\")\\\n",
    "                    .options(header=True)\\\n",
    "                    .load(\"file:///home/tamaghna/big_data_spark/sellers_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fb7619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders.drop(\"bill_raw_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19e9e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+\n",
      "|seller_id|avg(ratio)           |\n",
      "+---------+---------------------+\n",
      "|7        |2.5952287877881708E-5|\n",
      "|3        |1.62888537056594E-4  |\n",
      "|8        |9.213030375408861E-5 |\n",
      "|0        |2.0198858989469224E-5|\n",
      "|5        |4.211073965904022E-5 |\n",
      "|6        |4.782147194369122E-5 |\n",
      "|9        |3.837913136180238E-5 |\n",
      "|1        |1.9642333664610147E-4|\n",
      "|4        |3.296428039825817E-5 |\n",
      "|2        |6.690408001060484E-5 |\n",
      "+---------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.join(broadcast(sellers),orders.seller_id==sellers.seller_id,\"inner\")\\\n",
    "            .withColumn(\"ratio\",orders.num_pieces_sold/sellers.daily_target)\\\n",
    "            .groupBy(orders.seller_id).agg(avg(\"ratio\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba11ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [seller_id#281], [seller_id#291], Inner, BuildRight, false\n",
      ":- *(2) Filter isnotnull(seller_id#281)\n",
      ":  +- *(2) ColumnarToRow\n",
      ":     +- FileScan parquet [order_id#279,product_id#280,seller_id#281,date#282,num_pieces_sold#283] Batched: true, DataFilters: [isnotnull(seller_id#281)], Format: Parquet, Location: InMemoryFileIndex[file:/home/tamaghna/big_data_spark/sales_parquet], PartitionFilters: [], PushedFilters: [IsNotNull(seller_id)], ReadSchema: struct<order_id:string,product_id:string,seller_id:string,date:string,num_pieces_sold:string>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [id=#360]\n",
      "   +- *(1) Filter isnotnull(seller_id#291)\n",
      "      +- *(1) ColumnarToRow\n",
      "         +- FileScan parquet [seller_id#291,seller_name#292,daily_target#293] Batched: true, DataFilters: [isnotnull(seller_id#291)], Format: Parquet, Location: InMemoryFileIndex[file:/home/tamaghna/big_data_spark/sellers_parquet], PartitionFilters: [], PushedFilters: [IsNotNull(seller_id)], ReadSchema: struct<seller_id:string,seller_name:string,daily_target:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.join(broadcast(sellers),orders.seller_id==sellers.seller_id,\"inner\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56cbb81b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'autobroadcastjointhreshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4098/381765300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautobroadcastjointhreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'autobroadcastjointhreshold'"
     ]
    }
   ],
   "source": [
    "spark.conf.get(spark.sql.autobroadcastjointhreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689e8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
