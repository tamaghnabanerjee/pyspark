{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d6c945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 08:48:51,296 WARN util.Utils: Your hostname, tb-LinuxBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "2021-09-22 08:48:51,300 WARN util.Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2021-09-22 08:48:52,520 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"file-io\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648a62e",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16300dce",
   "metadata": {},
   "source": [
    "Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b03f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").options(header=True,inferSchema=True).load(\"/sparkdata/flightData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe6e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc03c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd936e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If we do not infer schema, then we can create a custom schema of the DF and then load the file in the DF.\\nBut for this, we ousl have to be aware of the data present in the dataset.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''If we do not infer schema, then we can create a custom schema of the DF and then load the file in the DF.\n",
    "But for this, we ousl have to be aware of the data present in the dataset.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0902261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").options(header=True).load(\"/sparkdata/flightData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "338cbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95815aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "                    .add(\"Destination_Country\",StringType(),False)\\\n",
    "                    .add(\"Origin_Country\",StringType(),False)\\\n",
    "                    .add(\"Flight_Count\",IntegerType(),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52c4d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").options(header=True).schema(schema=schema).load(\"/sparkdata/flightData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85af5b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------------+------------+\n",
      "|Destination_Country     |Origin_Country  |Flight_Count|\n",
      "+------------------------+----------------+------------+\n",
      "|United States           |Romania         |15          |\n",
      "|United States           |Croatia         |1           |\n",
      "|United States           |Ireland         |344         |\n",
      "|Egypt                   |United States   |15          |\n",
      "|United States           |India           |62          |\n",
      "|United States           |Singapore       |1           |\n",
      "|United States           |Grenada         |62          |\n",
      "|Costa Rica              |United States   |588         |\n",
      "|Senegal                 |United States   |40          |\n",
      "|Moldova                 |United States   |1           |\n",
      "|United States           |Sint Maarten    |325         |\n",
      "|United States           |Marshall Islands|39          |\n",
      "|Guyana                  |United States   |64          |\n",
      "|Malta                   |United States   |1           |\n",
      "|Anguilla                |United States   |41          |\n",
      "|Bolivia                 |United States   |30          |\n",
      "|United States           |Paraguay        |6           |\n",
      "|Algeria                 |United States   |4           |\n",
      "|Turks and Caicos Islands|United States   |230         |\n",
      "|United States           |Gibraltar       |1           |\n",
      "+------------------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 09:23:37,835 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count\n",
      " Schema: Destination_Country, Origin_Country, Flight_Count\n",
      "Expected: Destination_Country but found: DEST_COUNTRY_NAME\n",
      "CSV file: hdfs://localhost:9000/sparkdata/flightData.csv\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c04ffb",
   "metadata": {},
   "source": [
    "Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17aef591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out how many flights are there from India to United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f2e7b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Flight_Count|\n",
      "+------------+\n",
      "|          62|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 09:28:13,329 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count\n",
      " Schema: Destination_Country, Origin_Country, Flight_Count\n",
      "Expected: Destination_Country but found: DEST_COUNTRY_NAME\n",
      "CSV file: hdfs://localhost:9000/sparkdata/flightData.csv\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.Origin_Country==\"India\")&(df.Destination_Country==\"United States\")).select(df.Flight_Count).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3a29d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out where do flights go from India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "639e18d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+------------+\n",
      "|Destination_Country|      Origin_Country|Flight_Count|\n",
      "+-------------------+--------------------+------------+\n",
      "|      United States|             Romania|          15|\n",
      "|      United States|             Croatia|           1|\n",
      "|      United States|             Ireland|         344|\n",
      "|      United States|               India|          62|\n",
      "|      United States|           Singapore|           1|\n",
      "|      United States|             Grenada|          62|\n",
      "|      United States|        Sint Maarten|         325|\n",
      "|      United States|    Marshall Islands|          39|\n",
      "|      United States|            Paraguay|           6|\n",
      "|      United States|           Gibraltar|           1|\n",
      "|      United States|Federated States ...|          69|\n",
      "|      United States|              Russia|         161|\n",
      "|      United States|         Netherlands|         660|\n",
      "|      United States|             Senegal|          42|\n",
      "|      United States|              Angola|          13|\n",
      "|      United States|            Anguilla|          38|\n",
      "|      United States|             Ecuador|         300|\n",
      "|      United States|              Cyprus|           1|\n",
      "|      United States|            Portugal|         134|\n",
      "|      United States|          Costa Rica|         608|\n",
      "+-------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 09:29:47,228 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count\n",
      " Schema: Destination_Country, Origin_Country, Flight_Count\n",
      "Expected: Destination_Country but found: DEST_COUNTRY_NAME\n",
      "CSV file: hdfs://localhost:9000/sparkdata/flightData.csv\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Destination_Country==\"United States\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c58300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Destination_Country == 'United States', change it to \"USA\"\n",
    "# If Origin_Country == \"United States\", change it to \"USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b03a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d88d7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Destination_Country\", when(df.Destination_Country == \"United States\", \"USA\")\\\n",
    "                .otherwise(df.Destination_Country))\\\n",
    "    .withColumn(\"Origin_Country\", when(df.Origin_Country == \"United States\", \"USA\")\\\n",
    "                .otherwise(df.Origin_Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34a33923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+------------+\n",
      "| Destination_Country|  Origin_Country|Flight_Count|\n",
      "+--------------------+----------------+------------+\n",
      "|                 USA|         Romania|          15|\n",
      "|                 USA|         Croatia|           1|\n",
      "|                 USA|         Ireland|         344|\n",
      "|               Egypt|             USA|          15|\n",
      "|                 USA|           India|          62|\n",
      "|                 USA|       Singapore|           1|\n",
      "|                 USA|         Grenada|          62|\n",
      "|          Costa Rica|             USA|         588|\n",
      "|             Senegal|             USA|          40|\n",
      "|             Moldova|             USA|           1|\n",
      "|                 USA|    Sint Maarten|         325|\n",
      "|                 USA|Marshall Islands|          39|\n",
      "|              Guyana|             USA|          64|\n",
      "|               Malta|             USA|           1|\n",
      "|            Anguilla|             USA|          41|\n",
      "|             Bolivia|             USA|          30|\n",
      "|                 USA|        Paraguay|           6|\n",
      "|             Algeria|             USA|           4|\n",
      "|Turks and Caicos ...|             USA|         230|\n",
      "|                 USA|       Gibraltar|           1|\n",
      "+--------------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 09:52:58,808 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count\n",
      " Schema: Destination_Country, Origin_Country, Flight_Count\n",
      "Expected: Destination_Country but found: DEST_COUNTRY_NAME\n",
      "CSV file: hdfs://localhost:9000/sparkdata/flightData.csv\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393c028",
   "metadata": {},
   "source": [
    "write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cb037a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 09:57:49,867 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count\n",
      " Schema: Destination_Country, Origin_Country, Flight_Count\n",
      "Expected: Destination_Country but found: DEST_COUNTRY_NAME\n",
      "CSV file: hdfs://localhost:9000/sparkdata/flightData.csv\n"
     ]
    }
   ],
   "source": [
    "df.write.format(\"csv\").options(header=True).mode(\"overwrite\").save(\"/sparkdata/flights_data_transformed\")\n",
    "# This is stored as a directory and within it are success file and csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bc2c7",
   "metadata": {},
   "source": [
    "# Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b93fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/data/retail_db/categories/part-00000\")\n",
    "# Define schema in any of the below ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03780a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType()\\\n",
    "                     .add(\"S.No.\",IntegerType(),False)\\\n",
    "                     .add(\"Quantity.\",IntegerType(),True)\\\n",
    "                    .add(\"Category\",StringType(),False)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "235a17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "                    StructField(\"S.No.\",IntegerType(),False),\\\n",
    "                    StructField(\"Quantity\",IntegerType(),True),\\\n",
    "                    StructField(\"Category\",StringType(),False)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd895a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "            .options(header=True)\\\n",
    "            .schema(schema=schema)\\\n",
    "            .load(\"/data/retail_db/categories/part-00000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b5674ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------------------+\n",
      "|S.No.|Quantity|           Category|\n",
      "+-----+--------+-------------------+\n",
      "|    2|       2|             Soccer|\n",
      "|    3|       2|Baseball & Softball|\n",
      "|    4|       2|         Basketball|\n",
      "|    5|       2|           Lacrosse|\n",
      "|    6|       2|   Tennis & Racquet|\n",
      "|    7|       2|             Hockey|\n",
      "|    8|       2|        More Sports|\n",
      "|    9|       3|   Cardio Equipment|\n",
      "|   10|       3|  Strength Training|\n",
      "|   11|       3|Fitness Accessories|\n",
      "|   12|       3|       Boxing & MMA|\n",
      "|   13|       3|        Electronics|\n",
      "|   14|       3|     Yoga & Pilates|\n",
      "|   15|       3|  Training by Sport|\n",
      "|   16|       3|    As Seen on  TV!|\n",
      "|   17|       4|             Cleats|\n",
      "|   18|       4|     Men's Footwear|\n",
      "|   19|       4|   Women's Footwear|\n",
      "|   20|       4|     Kids' Footwear|\n",
      "|   21|       4|     Featured Shops|\n",
      "+-----+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 21:58:10,254 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: 1, 2, Football\n",
      " Schema: S.No., Quantity, Category\n",
      "Expected: S.No. but found: 1\n",
      "CSV file: hdfs://localhost:9000/data/retail_db/categories/part-00000\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4691ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save this file as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03a0bee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-22 21:59:56,227 WARN csv.CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: 1, 2, Football\n",
      " Schema: S.No., Quantity, Category\n",
      "Expected: S.No. but found: 1\n",
      "CSV file: hdfs://localhost:9000/data/retail_db/categories/part-00000\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.format(\"parquet\").mode(\"overwrite\").options(header=True).save(\"/sparkdata/categories.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8866841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parquet_file = /sparkdata/categories.parquet/part-00000-ee70d5b8-a569-4230-966c-1cc8650c3e1d-c000.snappy.parquet'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''parquet_file = /sparkdata/categories.parquet/part-00000-ee70d5b8-a569-4230-966c-1cc8650c3e1d-c000.snappy.parquet'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c37c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 30:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\").\\\n",
    "    load(\"/sparkdata/categories.parquet/part-00000-ee70d5b8-a569-4230-966c-1cc8650c3e1d-c000.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43ac2d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------------------+\n",
      "|S.No.|Quantity|           Category|\n",
      "+-----+--------+-------------------+\n",
      "|    2|       2|             Soccer|\n",
      "|    3|       2|Baseball & Softball|\n",
      "|    4|       2|         Basketball|\n",
      "|    5|       2|           Lacrosse|\n",
      "|    6|       2|   Tennis & Racquet|\n",
      "|    7|       2|             Hockey|\n",
      "|    8|       2|        More Sports|\n",
      "|    9|       3|   Cardio Equipment|\n",
      "|   10|       3|  Strength Training|\n",
      "|   11|       3|Fitness Accessories|\n",
      "|   12|       3|       Boxing & MMA|\n",
      "|   13|       3|        Electronics|\n",
      "|   14|       3|     Yoga & Pilates|\n",
      "|   15|       3|  Training by Sport|\n",
      "|   16|       3|    As Seen on  TV!|\n",
      "|   17|       4|             Cleats|\n",
      "|   18|       4|     Men's Footwear|\n",
      "|   19|       4|   Women's Footwear|\n",
      "|   20|       4|     Kids' Footwear|\n",
      "|   21|       4|     Featured Shops|\n",
      "+-----+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 31:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78049c",
   "metadata": {},
   "source": [
    "# json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ccde8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").options(header=True)\\\n",
    ".load(\"/data/retail_db_json/products/part-r-00000-158b7037-4a23-47e6-8cb3-8cbf878beff7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0217ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------+--------------------+--------------------+-------------+\n",
      "|product_category_id|product_description|product_id|       product_image|        product_name|product_price|\n",
      "+-------------------+-------------------+----------+--------------------+--------------------+-------------+\n",
      "|                  2|                   |         1|http://images.acm...|Quest Q64 10 FT. ...|        59.98|\n",
      "|                  2|                   |         2|http://images.acm...|Under Armour Men'...|       129.99|\n",
      "|                  2|                   |         3|http://images.acm...|Under Armour Men'...|        89.99|\n",
      "|                  2|                   |         4|http://images.acm...|Under Armour Men'...|        89.99|\n",
      "|                  2|                   |         5|http://images.acm...|Riddell Youth Rev...|       199.99|\n",
      "|                  2|                   |         6|http://images.acm...|Jordan Men's VI R...|       134.99|\n",
      "|                  2|                   |         7|http://images.acm...|Schutt Youth Recr...|        99.99|\n",
      "|                  2|                   |         8|http://images.acm...|Nike Men's Vapor ...|       129.99|\n",
      "|                  2|                   |         9|http://images.acm...|Nike Adult Vapor ...|         50.0|\n",
      "|                  2|                   |        10|http://images.acm...|Under Armour Men'...|       129.99|\n",
      "|                  2|                   |        11|http://images.acm...|Fitness Gear 300 ...|       209.99|\n",
      "|                  2|                   |        12|http://images.acm...|Under Armour Men'...|       139.99|\n",
      "|                  2|                   |        13|http://images.acm...|Under Armour Men'...|        89.99|\n",
      "|                  2|                   |        14|http://images.acm...|Quik Shade Summit...|       199.99|\n",
      "|                  2|                   |        15|http://images.acm...|Under Armour Kids...|        59.99|\n",
      "|                  2|                   |        16|http://images.acm...|Riddell Youth 360...|       299.99|\n",
      "|                  2|                   |        17|http://images.acm...|Under Armour Men'...|       129.99|\n",
      "|                  2|                   |        18|http://images.acm...|Reebok Men's Full...|        29.97|\n",
      "|                  2|                   |        19|http://images.acm...|Nike Men's Finger...|       124.99|\n",
      "|                  2|                   |        20|http://images.acm...|Under Armour Men'...|       129.99|\n",
      "+-------------------+-------------------+----------+--------------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ef618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
